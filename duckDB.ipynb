{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7abe7f8",
   "metadata": {},
   "source": [
    "# Getting Started with DuckDB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13367e1f",
   "metadata": {},
   "source": [
    "DuckDB is a modern, high-performance, in-memory analytical database management system (DBMS) designed to support \n",
    "complex analytical queries. It is a relational (table-oriented) DBMS that supports the Structured Query Language \n",
    "(SQL). DuckDB combines the simplicity and ease of use of SQLite with the high-performance capabilities required \n",
    "for analytical workloads, making it an excellent choice for data scientists and analysts.\n",
    "\n",
    "Key Features >>\n",
    "\n",
    "Simple operation: DuckDB is serverless, has no external dependencies, and is embedded within a host process. \n",
    "This makes it easy to install and deploy, requiring only a C++11 compiler for building.\n",
    "\n",
    "Feature-rich: It supports extensive SQL data management features. DuckDB also offers deep integration with Python \n",
    "and R, making it suitable for data science and interactive data analysis.\n",
    "\n",
    "Fast analytical queries: DuckDB uses a columnar-vectorized query execution engine optimized for analytics, enabling\n",
    "parallel query processing and efficient handling of large datasets. \n",
    "\n",
    "Free and open source: It is released under the permissive MIT License, making it free to use and open-source. \n",
    "\n",
    "Portability: With no external dependencies, DuckDB is highly portable and can run on various operating systems \n",
    "(Linux, macOS, Windows) and CPU architectures (x86, ARM). It can even run in web browsers using DuckDB-Wasm.\n",
    "\n",
    "Extensibility: DuckDB supports a flexible extension mechanism, allowing the addition of new data types, \n",
    "functions, file formats, and SQL syntax. \n",
    "\n",
    "Thorough testing: It undergoes intensive testing using Continuous Integration, with a test suite containing \n",
    "millions of queries. This ensures stability and reliability across different platforms and compilers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a620ffa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install duckdb --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b34fd1",
   "metadata": {},
   "source": [
    "In this section, we will learn to set up DuckDB, load CSV files, perform data analysis, and learn about relations and query functions. \n",
    "\n",
    "We will start by installing the DuckDB Python package. \n",
    "\n",
    "This line of code is a command used in the terminal or command prompt, not in a Python script.\n",
    "\n",
    "pip is a package installer for Python. It's used to install and manage software packages/libraries.\n",
    "\n",
    "install is a command that tells pip to install a package.\n",
    "\n",
    "duckdb is the name of the package that pip is being told to install.\n",
    "\n",
    "--upgrade is an optional argument that tells pip to upgrade the package if it's already installed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a0a0a0",
   "metadata": {},
   "source": [
    "# Creating the DuckDB database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8912c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "con = duckdb.connect(\"datacamp.duckdb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ee9c16",
   "metadata": {},
   "source": [
    "To create the persistent database, you just have to use the connect function and provide it with the database name. \n",
    "\n",
    "The code starts by importing the duckdb module, which is a fast analytical database written in C++.\n",
    "\n",
    "Then, it establishes a connection to a DuckDB database named \"datacamp.duckdb\" using the connect method.\n",
    "\n",
    "It will create a database base file in your local directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab72833",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.execute(\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS bank AS \n",
    "    SELECT * FROM read_csv('bank-marketing.csv')\n",
    "\"\"\")\n",
    "con.execute(\"SHOW ALL TABLES\").fetchdf()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "855905df",
   "metadata": {},
   "source": [
    "We will load a CSV file and create a \"bank\" table. The dataset we are using is available on DataLab and is called Bank Marketing. It consists of direct marketing campaigns by a Portuguese banking institution using phone calls.\n",
    "\n",
    "To load the CSV file, you have to create a Table first using SQL and then use the read_csv() function within the SQL script to load the file. It is that simple. \n",
    "\n",
    "We will then validate our table by executing the SQL script that shows all of the tables within the database and using the fetchdf function to display the result as a pandas DataFrame. \n",
    "\n",
    "The con.execute() function is used to execute SQL commands.\n",
    "\n",
    "The first con.execute() runs a CREATE TABLE SQL command.\n",
    "\n",
    "IF NOT EXISTS checks if the table 'bank' already exists, and if it does, the command is ignored.\n",
    "\n",
    "AS SELECT * FROM read_csv('bank-marketing.csv') creates the 'bank' table using data from the CSV file.\n",
    "\n",
    "The read_csv() function reads the 'bank-marketing.csv' file.\n",
    "\n",
    "The second con.execute() runs a SHOW ALL TABLES SQL command.\n",
    "\n",
    "fetchdf() fetches the result of the SHOW ALL TABLES command as a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89c2b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.execute(\"SELECT * FROM bank WHERE duration < 100 LIMIT 5\").fetchdf()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a766d7",
   "metadata": {},
   "source": [
    "Now that we have successfully created our first table, we will run a beginner-level query to analyze the data and display the result as a DataFrame.\n",
    "\n",
    "con.execute() is a method that runs the SQL query enclosed in the parentheses.\n",
    "\n",
    "\"SELECT * FROM bank WHERE duration &lt; 100 LIMIT 5\" is the SQL query being executed.\n",
    "\n",
    "SELECT * FROM bank selects all columns from the 'bank' table.\n",
    "\n",
    "WHERE duration &lt; 100 filters the data to only include rows where the 'duration' is less than 100.\n",
    "\n",
    "LIMIT 5 restricts the output to the first 5 rows that match the condition.\n",
    "\n",
    ".fetchdf() is a method that fetches the result of the query and returns it as a DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "907b53fb",
   "metadata": {},
   "source": [
    "# DuckDB Relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7156169b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_duck = duckdb.read_csv(\"bank-marketing.csv\",sep=\";\")\n",
    "bank_duck.filter(\"duration < 100\").limit(3).df()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "244282bc",
   "metadata": {},
   "source": [
    "DuckDB relations are essentially tables that can be queried using the Relational API. This API allows for the chaining of various query operations on data sources like Pandas DataFrames. Instead of using SQL queries, you will by chaining together various Python functions to analyze the data. \n",
    "\n",
    "For example, we will load a CSV file to create the DuckDB relation. To analyze the table, you can chain the filter and limit functions.\n",
    "\n",
    "The code uses the duckdb library, which is a high-performance analytical database system.\n",
    "\n",
    "duckdb.read_csv(\"bank-marketing.csv\",sep=\";\") reads a CSV file named \"bank-marketing.csv\" using a semicolon as a separator.\n",
    "\n",
    "The read CSV file is stored in the bank_duck variable.\n",
    "\n",
    "bank_duck.filter(\"duration &lt; 100\") filters the data to only include rows where the \"duration\" column is less than 100.\n",
    "\n",
    ".limit(3) further limits the output to the first 3 rows of the filtered data.\n",
    "\n",
    ".df() converts the result into a pandas DataFrame, which is a two-dimensional, size-mutable, and heterogeneous tabular data structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292b5900",
   "metadata": {},
   "outputs": [],
   "source": [
    "rel = con.table(\"bank\")\n",
    "rel.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab262ea",
   "metadata": {},
   "source": [
    "We can also create relations by loading the table from the DuckDB database. \n",
    "\n",
    "The code is using a database connection object con to access a table named \"bank\".\n",
    "\n",
    "rel = con.table(\"bank\") is accessing the \"bank\" table from the database and storing it in rel.\n",
    "\n",
    "rel.columns is then used to display the column names of the \"bank\" table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d2bf6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rel.filter(\"duration < 100\").project(\"job,education,loan\").order(\"job\").limit(3).df()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f04497c7",
   "metadata": {},
   "source": [
    "Let’s write a relation that uses multiple functions to analyze the data. \n",
    "\n",
    "rel.filter(\"duration &lt; 100\") filters the data to include only rows where the 'duration' value is less than 100.\n",
    "\n",
    ".project(\"job,education,loan\") selects only the 'job', 'education', and 'loan' columns from the filtered data.\n",
    "\n",
    ".order(\"job\") sorts the data based on the 'job' column in ascending order.\n",
    "\n",
    ".limit(3) limits the output to the first 3 rows of the sorted data.\n",
    "\n",
    ".df() converts the result into a pandas DataFrame.\n",
    "\n",
    "We have three rows and columns sorted by job and filtered by duration column."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2517031c",
   "metadata": {},
   "source": [
    "# DuckDB Query Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23416282",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = duckdb.query(\"\"\"SELECT \n",
    "                            job,\n",
    "                            COUNT(*) AS total_clients_contacted,\n",
    "                            AVG(duration) AS avg_campaign_duration,\n",
    "                        FROM \n",
    "                            'bank-marketing.csv'\n",
    "                        WHERE \n",
    "                            age > 30\n",
    "                        GROUP BY \n",
    "                            job\n",
    "                        ORDER BY \n",
    "                            total_clients_contacted DESC;\"\"\")\n",
    "res.df()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba95dd14",
   "metadata": {},
   "source": [
    "The DuckDB query function allows SQL queries to be executed within the database, returning results that can be converted into various formats for further analysis.\n",
    "\n",
    "In the code example, we are running the SQL query to find out the job titles of clients over the age of 30, count the number of clients contacted for each job, and calculate the average duration of the campaign.\n",
    "\n",
    "The code is written in SQL and is executed using the DuckDB Python library.\n",
    "\n",
    "res = duckdb.query(\"\"\"...\"\"\") is running an SQL query and storing the result in the variable res.\n",
    "\n",
    "SELECT job, COUNT(*) AS total_clients_contacted, AVG(duration) AS avg_campaign_duration is selecting the 'job' column, the count of rows (renamed as 'total_clients_contacted'), and the average of the 'duration' column (renamed as 'avg_campaign_duration').\n",
    "\n",
    "FROM 'bank-marketing.csv' is specifying the data source, a CSV file named 'bank-marketing.csv'.\n",
    "\n",
    "WHERE age &gt; 30 is filtering the data to only include rows where the 'age' column is greater than 30.\n",
    "\n",
    "GROUP BY job is grouping the selected data by the 'job' column.\n",
    "\n",
    "ORDER BY total_clients_contacted DESC is ordering the result in descending order based on the 'total_clients_contacted' column.\n",
    "\n",
    "res.df() is converting the result into a pandas DataFrame for easier manipulation and analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003db1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "380ba640",
   "metadata": {},
   "source": [
    "We will now close the connection to the database and release any resources associated with that connection, preventing potential memory and file handle leaks.\n",
    "\n",
    "This is a single line of code that closes the connection to a database.\n",
    "\n",
    "con is the variable representing the database connection.\n",
    "\n",
    ".close() is a method used to terminate the connection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96325baa",
   "metadata": {},
   "source": [
    "# Building a RAG Application with DuckDB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea1379c0",
   "metadata": {},
   "source": [
    "In the first project, we will learn to build an RAG application with LlamaIndex and use DuckDB as a Vector database and retriever. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c563b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%pip install duckdb\n",
    "%pip install llama-index\n",
    "%pip install llama-index-vector-stores-duckdb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46198d0d",
   "metadata": {},
   "source": [
    "Install all the necessary Python packages that will be used to create and retrieve the index. \n",
    "\n",
    "The %%capture command is a Jupyter notebook magic command that suppresses the output of the cell.\n",
    "\n",
    "The %pip install duckdb command installs the DuckDB library, an in-memory analytical database.\n",
    "\n",
    "The %pip install llama-index command installs the Llama Index library, a Python library for indexing.\n",
    "\n",
    "The %pip install llama-index-vector-stores-duckdb command installs a specific component of the Llama Index library that integrates with DuckDB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7210dfbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader\n",
    "from llama_index.vector_stores.duckdb import DuckDBVectorStore\n",
    "from llama_index.core import StorageContext\n",
    "\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ca16bb",
   "metadata": {},
   "source": [
    "Import the necessary Python package with the functions.\n",
    "\n",
    "The code imports the VectorStoreIndex and SimpleDirectoryReader classes from the llama_index.core module.\n",
    "\n",
    "It then imports the DuckDBVectorStore class from the llama_index.vector_stores.duckdb module.\n",
    "\n",
    "The StorageContext class is also imported from the llama_index.core module.\n",
    "\n",
    "Finally, the Markdown and display functions are imported from the IPython.display module."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4582f316",
   "metadata": {},
   "source": [
    "# Setting up GPT-4o and Embedding Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa94dbf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from llama_index.llms.openai import OpenAI\n",
    "\n",
    "os.environ[\"OPEN_AI_API_KEY\"] = \"OPEN_AI_API_KEY\"\n",
    "llm = OpenAI(model=\"gpt-4\", api_key=\"OPEN_AI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa7b9a03",
   "metadata": {},
   "source": [
    "For a language model, we will use the latest GPT4o model and the OpenAI API. To create the large language model (LLM) client, you just have to provide a model name and API key. \n",
    "\n",
    "The code begins by importing the 'os' module, which provides functions for interacting with the operating system.\n",
    "\n",
    "Then, it imports the 'OpenAI' class from the 'llama_index.llms.openai' module.\n",
    "\n",
    "It creates an instance 'llm' of the 'OpenAI' class.\n",
    "\n",
    "The 'OpenAI' class is initialized with two parameters: 'model' and 'api_key'.\n",
    "\n",
    "The 'model' parameter is set to \"gpt-4o\", which is the name of the model to be used.\n",
    "\n",
    "The 'api_key' parameter is retrieved from the environment variables using 'os.environ[\"OPENAI_API_KEY\"]'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36cb8c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "embed_model = OpenAIEmbedding(\n",
    "    model=\"text-embedding-3-small\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c59ad1",
   "metadata": {},
   "source": [
    "Then, we will create the embed model client using the OpenAI text-embedding-3-small model. \n",
    "\n",
    "The code starts with importing the OpenAIEmbedding class from the llama_index.embeddings.openai module.\n",
    "\n",
    "Then, it creates an instance of the OpenAIEmbedding class named embed_model.\n",
    "\n",
    "While creating the instance, it passes \"text-embedding-3-small\" as an argument to the model parameter of the OpenAIEmbedding class.\n",
    "\n",
    "The embed_model instance can now be used to generate embeddings for text data using the specified OpenAI model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "014563ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import Settings\n",
    "\n",
    "Settings.llm = llm\n",
    "Settings.embed_model = embed_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3604ed4b",
   "metadata": {},
   "source": [
    "We will make OpenAI LLM and Embedding models global for all LlamaIndex functions to use. In short, these models will be set as default.\n",
    "\n",
    "The code begins with importing the Settings class from the llama_index.core module.\n",
    "\n",
    "The Settings class is likely a configuration class for the llama_index package.\n",
    "\n",
    "The llm object is assigned to the llm attribute of the Settings class.\n",
    "\n",
    "The embed_model object is assigned to the embed_model attribute of the Settings class.\n",
    "\n",
    "These assignments are probably used to configure the behavior of the llama_index package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c407ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = SimpleDirectoryReader(\"Data\").load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "123dce52",
   "metadata": {},
   "source": [
    "For our project, we will load the PDF files from the data folder. These PDF files are tutorials from DataCamp that are saved as PDF files using the browser’s print function. \n",
    "\n",
    "Provide the folder directory to the SimpleDirectoryReader function and load the data. \n",
    "\n",
    "The code is written in Python and it's using a class named SimpleDirectoryReader.\n",
    "\n",
    "SimpleDirectoryReader(\"Data\") creates an instance of the SimpleDirectoryReader class.\n",
    "\n",
    "The string \"Data\" is passed as an argument, which is likely the name of the directory to be read.\n",
    "\n",
    "The method load_data() is called on the instance, which presumably loads the data from the specified directory.\n",
    "\n",
    "The loaded data is then stored in the variable documents."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67263054",
   "metadata": {},
   "source": [
    "# Using DuckDB as a vector database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9205db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store = DuckDBVectorStore(database_name = \"datacamp.duckdb\",table_name = \"blog\",persist_dir=\"./\", embed_dim=1536)\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "\n",
    "index = VectorStoreIndex.from_documents(\n",
    "    documents, storage_context=storage_context\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "079dc558",
   "metadata": {},
   "source": [
    "Then, create the vector store called “blog” using an existing database called “datacamp.duckdb.” After that, convert the PDF's data into embeddings and store them in the vector store. \n",
    "\n",
    "The first line creates an instance of DuckDBVectorStore with specified database and table names, a directory for persistence, and embedding dimension.\n",
    "\n",
    "The second line creates a StorageContext using the default settings and the previously created vector_store.\n",
    "\n",
    "The final line creates a VectorStoreIndex from a list of documents, using the previously created storage_context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b26211",
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "con = duckdb.connect(\"datacamp.duckdb\")\n",
    "\n",
    "con.execute(\"SHOW ALL TABLES\").fetchdf()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5acc781",
   "metadata": {},
   "source": [
    "To check if our vector store was successfully created, we will connect the database using the DuckDB Python API and run the SQL query to display all the tables in the database. \n",
    "\n",
    "The code starts by importing the duckdb module, which is a high-performance analytical database system.\n",
    "\n",
    "The duckdb.connect(\"datacamp.duckdb\") line establishes a connection to a DuckDB database file named \"datacamp.duckdb\".\n",
    "\n",
    "con.execute(\"SHOW ALL TABLES\") sends a SQL command to the database to retrieve all table names.\n",
    "\n",
    "The .fetchdf() method is then used to fetch the result of the SQL command as a pandas DataFrame.\n",
    "\n",
    "We have two tables: a “bank” promotional table and a “blog” table, which is a vector store. The “blog” table has an “embedding” column where all the embeddings are stored."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad1b8dc",
   "metadata": {},
   "source": [
    "# Creating a simple RAG application"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c288ce",
   "metadata": {},
   "source": [
    "Convert the index into the query engine, which will automatically first search the vector database for similar documents and use the additional context to generate the response. \n",
    "\n",
    "To test the RAG query engine, we will ask the question about the tutorial. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639c1221",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine = index.as_query_engine()\n",
    "response = query_engine.query(\"Who wrote 'GitHub Actions and MakeFile: A Hands-on Introduction'?\")\n",
    "display(Markdown(f\"<b>{response}</b>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8422db9c",
   "metadata": {},
   "source": [
    "The first line creates a query engine from an index object using the as_query_engine() method.\n",
    "\n",
    "The second line uses the query() method of the query engine to search for the author of a specific article.\n",
    "\n",
    "The third line uses the Markdown function to format the response in bold, and display function to show it.\n",
    "\n",
    "The output of the query is \"The author of \"GitHub Actions and MakeFile: A Hands-on Introduction\" is Abid Ali Awan.\" which is the correct answer "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8007314",
   "metadata": {},
   "source": [
    "# Creating a RAG chatbot with memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d711e6",
   "metadata": {},
   "source": [
    "Now, let’s create an advanced RAG application that uses the conversation history to generate the response. For that, we have to create a chat memory buffer and then a chat engine with memory, LLM, and vector store retriever. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4392e517",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.memory import ChatMemoryBuffer\n",
    "from llama_index.core.chat_engine import CondensePlusContextChatEngine\n",
    "\n",
    "memory = ChatMemoryBuffer.from_defaults(token_limit=3900)\n",
    "\n",
    "chat_engine = CondensePlusContextChatEngine.from_defaults(\n",
    "    index.as_retriever(),\n",
    "    memory=memory,\n",
    "    llm=llm\n",
    ")\n",
    "\n",
    "response = chat_engine.chat(\n",
    "    \"What is the easiest way of finetuning the Llama 3 model? Please provide step-by-step instructions.\"\n",
    ")\n",
    "\n",
    "display(Markdown(response.response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a181bb",
   "metadata": {},
   "source": [
    "The code starts by importing ChatMemoryBuffer from llama_index.core.memory.\n",
    "\n",
    "It also imports CondensePlusContextChatEngine from llama_index.core.chat_engine.\n",
    "\n",
    "A ChatMemoryBuffer object is created with a token limit of 3900.\n",
    "\n",
    "A CondensePlusContextChatEngine object is created using default settings, the previously created memory buffer, and llm.\n",
    "\n",
    "The chat method of chat_engine is called with a question about fine-tuning the Llama 3 model.\n",
    "\n",
    "The response from the chat engine is displayed using the Markdown function.\n",
    "\n",
    "We asked the chat engine how to fine-tune the Llama 3 model, and it used the vector store to give a highly accurate answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2255dffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chat_engine.chat(\n",
    "    \"Could you please provide more details about the Post Fine-Tuning Steps?\"\n",
    ")\n",
    "display(Markdown(response.response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "880c5923",
   "metadata": {},
   "source": [
    "To check if the memory buffer is working correctly, we will ask a follow-up question. \n",
    "\n",
    "The code is using a chat engine, which is likely an AI model, to generate a response to a given input.\n",
    "\n",
    "The method chat_engine.chat() is called with a string argument, which is the question to be asked.\n",
    "\n",
    "The response from the chat engine is stored in the variable response.\n",
    "\n",
    "Markdown(response.response) is used to format the response text in Markdown, a lightweight markup language.\n",
    "\n",
    "The display() function is then used to display the formatted text in the output.\n",
    "\n",
    "The chat engine remembered the previous conversation and responded accordingly. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c10666",
   "metadata": {},
   "source": [
    "# Building a DuckDB SQL Query Engine Using an LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "388461fa",
   "metadata": {},
   "source": [
    "In the second project, we will use DuckDB as an SQL query engine. This involves integrating the database engine with the GPT-4o model to generate natural language responses to questions about the database. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4334ea8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install duckdb-engine -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a465bea",
   "metadata": {},
   "source": [
    "Install duckdb-engine to create a database engine using SQLAlchemy.\n",
    "\n",
    "The code is using the %pip command, which is a magic command in Jupyter notebooks.\n",
    "\n",
    "The install argument tells pip to install a package.\n",
    "\n",
    "duckdb-engine is the name of the package that is being installed.\n",
    "\n",
    "The -q flag is used to run the command in quiet mode, reducing the output displayed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3200cb1",
   "metadata": {},
   "source": [
    "# Loading the DuckDB database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d9d572",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "\n",
    "engine = create_engine(\"duckdb:///datacamp.duckdb\")\n",
    "with engine.connect() as connection:\n",
    "    cursor = connection.exec_driver_sql(\"SELECT * FROM bank LIMIT 3\")\n",
    "    print(cursor.fetchall())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38bb0a6b",
   "metadata": {},
   "source": [
    "We will load the DuckDB database using the create_engine function and then write a simple SQL query to check whether it is successfully loaded.\n",
    "\n",
    "The code begins by importing the create_engine function from the sqlalchemy module.\n",
    "\n",
    "create_engine is then used to create an engine that connects to a DuckDB database file named datacamp.duckdb.\n",
    "\n",
    "with engine.connect() is used to establish a connection to the database.\n",
    "\n",
    "Inside the with block, connection.exec_driver_sql(\"SELECT * FROM bank LIMIT 3\") is executed.\n",
    "\n",
    "This SQL query selects all columns from the first three rows of the 'bank' table in the database.\n",
    "\n",
    "The results of the query are fetched with cursor.fetchall() and then printed to the console.\n",
    "\n",
    "Prefect. Our DuckDB database engine is ready to be used. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c61f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "[(56, 'housemaid', 'married', 'basic.4y', 'no', 'no', 'no', 'telephone', 'may', 'mon', 261, 1, 999, 0, 'nonexistent', 1.1, 93.994, -36.4, 4.857, 5191.0, 'no'), (57, 'services', 'married', 'high.school', 'unknown', 'no', 'no', 'telephone', 'may', 'mon', 149, 1, 999, 0, 'nonexistent', 1.1, 93.994, -36.4, 4.857, 5191.0, 'no'), (37, 'services', 'married', 'high.school', 'no', 'yes', 'no', 'telephone', 'may', 'mon', 226, 1, 999, 0, 'nonexistent', 1.1, 93.994, -36.4, 4.857, 5191.0, 'no')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b42ccbd",
   "metadata": {},
   "source": [
    "The provided Python code is a list of tuples.\n",
    "\n",
    "Each tuple in the list contains 21 elements.\n",
    "\n",
    "These elements could represent different attributes of a dataset, such as age, job, marital status, education, etc.\n",
    "\n",
    "The data types of the elements in the tuples vary, including integers, strings, and floating-point numbers.\n",
    "\n",
    "The data seems to be structured and could be used for further analysis or processing in a program."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7043ec68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import SQLDatabase\n",
    "\n",
    "sql_database = SQLDatabase(engine, include_tables=[\"bank\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5eee8c2",
   "metadata": {},
   "source": [
    "Now, we have to create a database Tool using the SQLDatabase function. Provide it with an engine object and table name.\n",
    "\n",
    "The code begins by importing the SQLDatabase class from the llama_index.core module.\n",
    "\n",
    "Then, an instance of the SQLDatabase class is created, named sql_database.\n",
    "\n",
    "The SQLDatabase instance is initialized with two arguments: engine and include_tables.\n",
    "\n",
    "engine is a previously defined variable that represents the database engine to be used.\n",
    "\n",
    "include_tables is a list of tables to be included in the database, in this case, only the \"bank\" table."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de2d606",
   "metadata": {},
   "source": [
    "# Building the SQL query engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23000445",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.query_engine import NLSQLTableQueryEngine\n",
    "\n",
    "query_engine = NLSQLTableQueryEngine(sql_database)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c66c89",
   "metadata": {},
   "source": [
    "Create the SQL query engine using the NLSQLTableQueryEngine function by providing it with the LlamaIndex SQL database object. \n",
    "\n",
    "The code begins by importing the NLSQLTableQueryEngine class from the llama_index.core.query_engine module.\n",
    "\n",
    "Then, an instance of the NLSQLTableQueryEngine class is created, named query_engine.\n",
    "\n",
    "This instance is initialized with the sql_database parameter, which presumably represents a SQL database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d6a076",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = query_engine.query(\"Which is the longest running campaign?\")\n",
    "\n",
    "print(response.response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20cad946",
   "metadata": {},
   "source": [
    "Ask the question from the query engine about the “bank” table in the natural language. \n",
    "\n",
    "The first line calls the query method of the query_engine object with the question \"Which is the longest running campaign?\".\n",
    "\n",
    "The query method presumably sends this question to a database or search engine and returns the result.\n",
    "\n",
    "This result is stored in the variable response.\n",
    "\n",
    "The second line prints the response attribute of the response object, which likely contains the answer to the query.\n",
    "\n",
    "In response, we will get the answer to your query in natural languages as \"The longest running campaign in the database has a duration of 4918 days.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6a1a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = query_engine.query(\"Which type of job has the most housing loan?\")\n",
    "\n",
    "print(response.response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd24d298",
   "metadata": {},
   "source": [
    "Let's ask a complex question.\n",
    "\n",
    "\"The job type with the most housing loans is 'admin.' with 5559 housing loans. This is followed by 'blue-collar' with 4710 housing loans and 'technician' with 3616 housing loans. Other job types with significant housing loans include 'services', 'management', 'retired', 'entrepreneur', and 'self-employed'.\" \n",
    "\n",
    "The above answer is precise, with additional information. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa7f21f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response.metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab1c832",
   "metadata": {},
   "source": [
    "To check what is going on on the back end, we will print the metadata. \n",
    "\n",
    "The code is written in Python, a high-level, interpreted programming language.\n",
    "\n",
    "The print() function is a built-in Python function used to output data to the console.\n",
    "\n",
    "response is an object that presumably holds some data, including a metadata attribute.\n",
    "\n",
    "response.metadata is accessing the metadata attribute of the response object.\n",
    "\n",
    "The code will print the value of response.metadata to the console."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb05aec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "{'d4ddf03c-337e-4ee6-957a-5fd2cfaa4b1c': {}, 'sql_query': \"SELECT job, COUNT(housing) AS housing_loan_count\\nFROM bank\\nWHERE housing = 'yes'\\nGROUP BY job\\nORDER BY housing_loan_count DESC;\", 'result': [('admin.', 5559), ('blue-collar', 4710), ('technician', 3616), ('services', 2050), ('management', 1490), ('retired', 892), ('entrepreneur', 779), ('self-employed', 740), ('unemployed', 557), ('housemaid', 540), ('student', 471), ('unknown', 172)], 'col_keys': ['job', 'housing_loan_count']}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c177ab43",
   "metadata": {},
   "source": [
    "The code is a SQL query embedded in a Python dictionary.\n",
    "\n",
    "The key 'sql_query' contains the actual SQL command.\n",
    "\n",
    "\"SELECT job, COUNT(housing) AS housing_loan_count\" selects the 'job' column and counts the 'housing' column.\n",
    "\n",
    "\"FROM bank\" specifies the table 'bank' from which the data is selected.\n",
    "\n",
    "\"WHERE housing = 'yes'\" filters the data to only include rows where 'housing' is 'yes'.\n",
    "\n",
    "\"GROUP BY job\" groups the data by the 'job' column.\n",
    "\n",
    "\"ORDER BY housing_loan_count DESC\" sorts the data in descending order by the count of 'housing'.\n",
    "\n",
    "The 'result' key in the dictionary stores the result of the SQL query.\n",
    "\n",
    "The 'col_keys' key in the dictionary stores the column names of the result.\n",
    "\n",
    "As we can see, GPT-4o first generates the SQL query, runs the query to get the result, and uses the result to generate the response. This multi-step process is achieved through two lines of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ecf00e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24b0de74",
   "metadata": {},
   "source": [
    "Close the engine when you are done with the project. \n",
    "\n",
    "This is a single line of Python code that calls the close() method on an object named engine.\n",
    "\n",
    "The close() method is commonly used to close a connection or a file.\n",
    "\n",
    "In this context, it's likely that engine is a database engine or a connection to a database.\n",
    "\n",
    "By calling engine.close(), the code is closing the connection to the database to free up resources."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
